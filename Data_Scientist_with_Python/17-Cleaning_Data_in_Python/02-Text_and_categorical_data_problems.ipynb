{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Section 02: Common data problems`\n",
    "### 01-Finding consistency\n",
    "* Print the `categories` DataFrame and take a close look at all possible correct categories of the survey columns.\n",
    "* Print the unique values of the survey columns in `airlines` using the `.unique()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>115</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>135</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>70</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>190</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>559</td>\n",
       "      <td>Unacceptable</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>4  1475</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>NEW YORK-JFK</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>280</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>5  2222</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>PHOENIX</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>165</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>6  2684</td>\n",
       "      <td>Friday</td>\n",
       "      <td>UNITED</td>\n",
       "      <td>ORLANDO</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 70-90</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>92</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>7  2549</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>JETBLUE</td>\n",
       "      <td>LONG BEACH</td>\n",
       "      <td>West US</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>95</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>8  2162</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>CHINA EASTERN</td>\n",
       "      <td>QINGDAO</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Large</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>220</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2477 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        day        airline        destination    dest_region  \\\n",
       "0       1351    Tuesday    UNITED INTL             KANSAI           Asia   \n",
       "1        373     Friday         ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
       "2       2820   Thursday          DELTA        LOS ANGELES        West US   \n",
       "3       1157    Tuesday      SOUTHWEST        LOS ANGELES        West US   \n",
       "4       2992  Wednesday       AMERICAN              MIAMI        East US   \n",
       "..       ...        ...            ...                ...            ...   \n",
       "280  4  1475    Tuesday         ALASKA       NEW YORK-JFK        East US   \n",
       "280  5  2222   Thursday      SOUTHWEST            PHOENIX        West US   \n",
       "280  6  2684     Friday         UNITED            ORLANDO        East US   \n",
       "280  7  2549    Tuesday        JETBLUE         LONG BEACH        West US   \n",
       "280  8  2162   Saturday  CHINA EASTERN            QINGDAO           Asia   \n",
       "\n",
       "    dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
       "0         Hub  Gates 91-102  12/31/2018       115           Clean   \n",
       "1       Small   Gates 50-59  12/31/2018       135           Clean   \n",
       "2         Hub   Gates 40-48  12/31/2018        70         Average   \n",
       "3         Hub   Gates 20-39  12/31/2018       190           Clean   \n",
       "4         Hub   Gates 50-59  12/31/2018       559    Unacceptable   \n",
       "..        ...           ...         ...       ...             ...   \n",
       "280       Hub   Gates 50-59  12/31/2018       280  Somewhat clean   \n",
       "280       Hub   Gates 20-39  12/31/2018       165           Clean   \n",
       "280       Hub   Gates 70-90  12/31/2018        92           Clean   \n",
       "280     Small    Gates 1-12  12/31/2018        95           Clean   \n",
       "280     Large    Gates 1-12  12/31/2018       220           Clean   \n",
       "\n",
       "            safety        satisfaction  \n",
       "0          Neutral      Very satisfied  \n",
       "1        Very safe      Very satisfied  \n",
       "2    Somewhat safe             Neutral  \n",
       "3        Very safe  Somewhat satisfied  \n",
       "4        Very safe  Somewhat satisfied  \n",
       "..             ...                 ...  \n",
       "280        Neutral  Somewhat satisfied  \n",
       "280      Very safe      Very satisfied  \n",
       "280      Very safe      Very satisfied  \n",
       "280  Somewhat safe      Very satisfied  \n",
       "280      Very safe  Somewhat satisfied  \n",
       "\n",
       "[2477 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "categories = pd.read_csv(\"datasets/categories.csv\", index_col=0)\n",
    "airlines = pd.read_csv(\"datasets/airlines.csv\",index_col=0)\n",
    "airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cleanliness           safety          satisfaction\n",
      "0           Clean          Neutral        Very satisfied\n",
      "1         Average        Very safe               Neutral\n",
      "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
      "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
      "4           Dirty  Somewhat unsafe      Very unsatisfied\n",
      "Cleanliness:  ['Clean' 'Average' 'Unacceptable' 'Somewhat clean' 'Somewhat dirty'\n",
      " 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satisfied' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print categories DataFrame\n",
    "print(categories)\n",
    "\n",
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ',airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* as shown in above output the column is inconsistent `cleanliness` because it has an `Unacceptable` category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a set out of the `cleanliness` column in `airlines` using `set()` and find the inconsistent category by finding the difference in the `cleanliness` column of `categories`.\n",
    "* Find rows of `airlines` with a `cleanliness` value not in `categories` and print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id        day           airline  destination  dest_region dest_size  \\\n",
      "4    2992  Wednesday          AMERICAN        MIAMI      East US       Hub   \n",
      "18   2913     Friday  TURKISH AIRLINES     ISTANBUL  Middle East       Hub   \n",
      "100  2321  Wednesday         SOUTHWEST  LOS ANGELES      West US       Hub   \n",
      "\n",
      "    boarding_area   dept_time  wait_min   cleanliness         safety  \\\n",
      "4     Gates 50-59  12/31/2018       559  Unacceptable      Very safe   \n",
      "18   Gates 91-102  12/31/2018       225  Unacceptable      Very safe   \n",
      "100   Gates 20-39  12/31/2018       130  Unacceptable  Somewhat safe   \n",
      "\n",
      "           satisfaction  \n",
      "4    Somewhat satisfied  \n",
      "18   Somewhat satisfied  \n",
      "100  Somewhat satisfied  \n"
     ]
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id        day           airline  destination  dest_region dest_size  \\\n",
      "4    2992  Wednesday          AMERICAN        MIAMI      East US       Hub   \n",
      "18   2913     Friday  TURKISH AIRLINES     ISTANBUL  Middle East       Hub   \n",
      "100  2321  Wednesday         SOUTHWEST  LOS ANGELES      West US       Hub   \n",
      "\n",
      "    boarding_area   dept_time  wait_min   cleanliness         safety  \\\n",
      "4     Gates 50-59  12/31/2018       559  Unacceptable      Very safe   \n",
      "18   Gates 91-102  12/31/2018       225  Unacceptable      Very safe   \n",
      "100   Gates 20-39  12/31/2018       130  Unacceptable  Somewhat safe   \n",
      "\n",
      "           satisfaction  \n",
      "4    Somewhat satisfied  \n",
      "18   Somewhat satisfied  \n",
      "100  Somewhat satisfied  \n",
      "          id       day        airline        destination    dest_region  \\\n",
      "0       1351   Tuesday    UNITED INTL             KANSAI           Asia   \n",
      "1        373    Friday         ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
      "2       2820  Thursday          DELTA        LOS ANGELES        West US   \n",
      "3       1157   Tuesday      SOUTHWEST        LOS ANGELES        West US   \n",
      "5        634  Thursday         ALASKA             NEWARK        East US   \n",
      "..       ...       ...            ...                ...            ...   \n",
      "280  4  1475   Tuesday         ALASKA       NEW YORK-JFK        East US   \n",
      "280  5  2222  Thursday      SOUTHWEST            PHOENIX        West US   \n",
      "280  6  2684    Friday         UNITED            ORLANDO        East US   \n",
      "280  7  2549   Tuesday        JETBLUE         LONG BEACH        West US   \n",
      "280  8  2162  Saturday  CHINA EASTERN            QINGDAO           Asia   \n",
      "\n",
      "    dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
      "0         Hub  Gates 91-102  12/31/2018       115           Clean   \n",
      "1       Small   Gates 50-59  12/31/2018       135           Clean   \n",
      "2         Hub   Gates 40-48  12/31/2018        70         Average   \n",
      "3         Hub   Gates 20-39  12/31/2018       190           Clean   \n",
      "5         Hub   Gates 50-59  12/31/2018       140  Somewhat clean   \n",
      "..        ...           ...         ...       ...             ...   \n",
      "280       Hub   Gates 50-59  12/31/2018       280  Somewhat clean   \n",
      "280       Hub   Gates 20-39  12/31/2018       165           Clean   \n",
      "280       Hub   Gates 70-90  12/31/2018        92           Clean   \n",
      "280     Small    Gates 1-12  12/31/2018        95           Clean   \n",
      "280     Large    Gates 1-12  12/31/2018       220           Clean   \n",
      "\n",
      "            safety        satisfaction  \n",
      "0          Neutral      Very satisfied  \n",
      "1        Very safe      Very satisfied  \n",
      "2    Somewhat safe             Neutral  \n",
      "3        Very safe  Somewhat satisfied  \n",
      "5        Very safe      Very satisfied  \n",
      "..             ...                 ...  \n",
      "280        Neutral  Somewhat satisfied  \n",
      "280      Very safe      Very satisfied  \n",
      "280      Very safe      Very satisfied  \n",
      "280  Somewhat safe      Very satisfied  \n",
      "280      Very safe  Somewhat satisfied  \n",
      "\n",
      "[2474 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])\n",
    "\n",
    "# Print rows with consistent categories only\n",
    "print(airlines[~cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Inconsistent categories\n",
    "* Print the unique values in `dest_region` and `dest_size` respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the capitalization of all values of `dest_region` to lowercase.\n",
    "* Replace the `'eur'` with `'europe'` in `dest_region` using the `.replace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Strip white spaces from the `dest_size` column using the `.strip()` method.\n",
    "* Verify that the changes have been into effect by printing the unique values of the columns using `.unique()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n",
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "airlines = pd.read_csv(\"datasets/airlines.csv\", index_col=0)\n",
    "\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03-Remapping categories\n",
    "* Create the ranges and labels for the `wait_type` column mentioned in the description.\n",
    "* Create the `wait_type` column by from `wait_min` by using `pd.cut()`, while inputting `label_ranges` and `label_names` in the correct arguments.\n",
    "* Create the `mapping` dictionary mapping weekdays to `'weekday'` and weekend days to `'weekend'`.\n",
    "* Create the `day_week` column by using `.replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_min</th>\n",
       "      <th>wait_type</th>\n",
       "      <th>day</th>\n",
       "      <th>day_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>medium</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135</td>\n",
       "      <td>medium</td>\n",
       "      <td>Friday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>medium</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>long</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>559</td>\n",
       "      <td>long</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>280</td>\n",
       "      <td>long</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>165</td>\n",
       "      <td>medium</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>92</td>\n",
       "      <td>medium</td>\n",
       "      <td>Friday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>95</td>\n",
       "      <td>medium</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>220</td>\n",
       "      <td>long</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2477 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     wait_min wait_type        day day_week\n",
       "0         115    medium    Tuesday  weekday\n",
       "1         135    medium     Friday  weekday\n",
       "2          70    medium   Thursday  weekday\n",
       "3         190      long    Tuesday  weekday\n",
       "4         559      long  Wednesday  weekday\n",
       "..        ...       ...        ...      ...\n",
       "280       280      long    Tuesday  weekday\n",
       "280       165    medium   Thursday  weekday\n",
       "280        92    medium     Friday  weekday\n",
       "280        95    medium    Tuesday  weekday\n",
       "280       220      long   Saturday  weekend\n",
       "\n",
       "[2477 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)\n",
    "airlines[['wait_min','wait_type','day','day_week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04- Removing titles and taking names\n",
    "\n",
    "* Remove `\"Dr.\"`, `\"Mr.\"`, `\"Miss\"` and `\"Ms.\"` from `full_name` by replacing them with an empty string `\"\"` in that order.\n",
    "* Run the `assert` statement using `.str.contains()` that tests whether `full_name` still contains any of the honorifics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = pd.read_csv(\"datasets/airlines_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\")\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05-Keeping it descriptive\n",
    "* Using the `airlines` DataFrame, store the length of each instance in the `survey_response` column in `resp_length` by using `.str.len()`.\n",
    "* Isolate the rows of `airlines` with `resp_length` higher than `40`.\n",
    "* Assert that the smallest `survey_response` length in `airlines_survey` is now bigger than `40`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = pd.read_csv(\"datasets/airlines_v3.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    The airport personnell forgot to alert us of d...\n",
      "19    The food in the airport was really really expe...\n",
      "20    One of the other travelers was really loud and...\n",
      "21    I don't remember answering the survey with the...\n",
      "22    The airport personnel kept ignoring my request...\n",
      "23    The chair I sat in was extremely uncomfortable...\n",
      "24    I wish you were more like other airports, the ...\n",
      "25    I was really unsatisfied with the wait times b...\n",
      "27    The flight was okay, but I didn't really like ...\n",
      "28    We were really slowed down by security measure...\n",
      "29    There was a spill on the aisle next to the bat...\n",
      "30    I felt very unsatisfied by how long the flight...\n",
      "Name: survey_response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Store length of each row in survey_response column\n",
    "resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey['survey_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================\n",
    "### `The End`  \n",
    "=================================="
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43798dc0310b2b2561b4c268d2ab658f1209d4eb0d367a12aa3b34e260041217"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
